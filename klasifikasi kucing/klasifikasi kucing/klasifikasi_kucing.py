# -*- coding: utf-8 -*-
"""Klasifikasi_ Kucing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g6aVumbAQtAHbSy7G_fGkpKNlCtgmbvP
"""

from google.colab import drive
drive.mount('/content/drive')

"""1. Setup

"""

#impor librari yang diperlukan
import os
import zipfile
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount(('/content/drive'))

"""2. Loading Dataset"""

#mengumpulkan path untuk direktori dasar
base_dir='/content/drive/MyDrive/klasifikasi kucing/dataset/' #Menentukan path direktori dasar yang berisi dataset kucing.
training_dir=os.path.join(base_dir, 'training') # menggabungkan direktori training dengan menggunakan os.path.join()
validation_dir=os.path.join(base_dir, 'validation')  #menggabungkan direktori validation dengan menggunakan os.path.join()

train_a_dir=os.path.join(training_dir,'abyssian') # untuk menggabungkan training_dir dengan
train_m_dir=os.path.join(training_dir,'munchkin') #untuk menggabungkan training_dir dengan
train_p_dir=os.path.join(training_dir,'persian') #untuk menggabungkan training_dir dengan
train_t_dir=os.path.join(training_dir,'toyger') #untuk menggabungkan training_dir dengan direktori toyger

valid_a_dir=os.path.join(validation_dir,'abyssian') # untuk menggabungkan validation_dir dengan direktori abyssian
valid_m_dir=os.path.join(validation_dir,'munchkin')# untuk menggabungkan validation_dir dengan direktori munchkin
valid_p_dir=os.path.join(validation_dir,'persian')# untuk menggabungkan validation_dir dengan direktori persian
valid_t_dir=os.path.join(validation_dir,'toyger')# untuk menggabungkan validation_dir dengan direktori toyger


#Let's find out the total number of horse and human images in the directories:
print('total abyssian in training: ', len(os.listdir(train_a_dir))) # untuk mencetak jumlah total gambar kucing ras Abyssinian dalam dataset pelatihan.
print('total munchkin in training: ', len(os.listdir(train_m_dir)))
print('total persian in training: ', len(os.listdir(train_p_dir)))
print('total toyger in training: ', len(os.listdir(train_t_dir)))

print('total abyssian in validation: ', len(os.listdir(valid_a_dir))) #  untuk mencetak jumlah total gambar kucing ras Abyssinian dalam dataset validasi.
print('total munchkin in validation: ', len(os.listdir(valid_m_dir)))
print('total persian in validation: ', len(os.listdir(valid_p_dir)))
print('total toyger in validation: ', len(os.listdir(valid_t_dir)))

"""3. One look at the dataset"""

#melihat file di direktori
train_a_names = os.listdir(train_a_dir) #mengakses direktori train_a_dir yang berisi gambar-gambar kucing ras Abyssinian dalam dataset pelatihan
print(train_a_names[:10])# mencetak 10 nama pertama dari daftar nama file yang ada dalam direktori train_a_dir
train_m_names = os.listdir(train_m_dir)
print(train_m_names[:10])
train_p_names = os.listdir(train_p_dir)
print(train_p_names[:10])
train_t_names = os.listdir(train_t_dir)
print(train_t_names[:10])


validation_a_names = os.listdir(valid_a_dir) #mengakses direktori valid_a_dir yang berisi gambar-gambar kucing ras Abyssinian dalam dataset validasi
print(validation_a_names[:10]) #mencetak 10 nama pertama dari daftar nama file yang ada dalam direktori valid_a_dir
validation_m_names = os.listdir(valid_m_dir)
print(validation_m_names[:10])
validation_p_names = os.listdir(valid_p_dir)
print(validation_p_names[:10])
validation_t_names = os.listdir(valid_t_dir)
print(validation_t_names[:10])

#lihat gambar yang ada di dataset.

import matplotlib.image as mpimg # untuk membaca, menampilkan, dan memanipulasi gambar menggunakan Matplotlib.
# Parameter untuk grafik , kami akan menampilkan gambar dalam konfigurasi 4x4
nrows = 4
ncols = 4

# Indeks untuk mengulangi gambar
pic_index = 0 #digunakan dalam pengulangan atau iterasi untuk mengontrol gambar mana yang akan diproses atau ditampilkan.

# Siapkan gambar matplotlib, dan sesuaikan ukurannya dengan foto 4x4
fig = plt.gcf() #digunakan untuk mendapatkan objek gambar saat ini (current figure) dari Matplotlib
fig.set_size_inches(ncols * 4, nrows * 4)#digunakan untuk mengatur ukuran gambar (figure) dalam satuan inci (inches).

pic_index += 4 # untuk menambahkan nilai 4 ke variabel pic_index
next_a_pix = [os.path.join(train_a_dir, fname) #digunakan untuk menggabungkan direktori train_a_dir dengan setiap fname dalam subset train_a_names[pic_index-4:pic_index]
                for fname in train_a_names[pic_index-4:pic_index]] #akan berisi daftar path untuk 4 gambar Abyssinian terakhir sebelum pic_index.
next_m_pix = [os.path.join(train_m_dir, fname)
                for fname in train_m_names[pic_index-4:pic_index]]
next_p_pix = [os.path.join(train_p_dir, fname)
                for fname in train_p_names[pic_index-4:pic_index]]
next_t_pix = [os.path.join(train_t_dir, fname)
                for fname in train_t_names[pic_index-4:pic_index]]

for i, img_path in enumerate(next_a_pix+next_m_pix+next_p_pix+next_t_pix):#melakukan pemrosesan yang diperlukan pada setiap gambar ras kucing yang ada dalam daftar path tersebut
  # Siapkan subplot; indeks subplot mulai dari 1
  sp = plt.subplot(nrows, ncols, i + 1) #digunakan untuk membuat dan mengatur subplot pada grid gambar.
  sp.axis('Off')#untuk menghilangkan sumbu (axis) pada subplot saat ini

  img = mpimg.imread(img_path)#untuk membaca gambar dari path yang diberikan menggunakan modul matplotlib.image (mpimg)
  plt.imshow(img) # untuk menampilkan gambar menggunakan modul matplotlib.pyplot (plt).

plt.show() #untuk menampilkan semua plot yang telah dibuat menggunakan modul matplotlib.pyplot (plt).

#Abyssian
#Munchkin
#Persian
#Tygor

"""4. Building a Model"""

model = tf.keras.models.Sequential([#untuk membuat model Sequential dalam framework Keras (yang diimpor dari TensorFlow, yang disingkat sebagai tf).
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(200, 200, 3)),#32 menunjukkan jumlah filter,(3,3) menunjukkan ukuran kernel filter,activation='relu menentukan fungsi aktivasi,activation='relu menentukan bentuk input pada lapisan pertama dari model CNN.
    tf.keras.layers.MaxPooling2D(2, 2), # menunjukkan ukuran jendela pooling yang digunakan
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    #setelah 6 lapisan kita menggunakan perataan untuk membuat vektor tunggal bersama dengan fungsi aktivasi

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1024, activation='relu'), # Ini adalah lapisan terhubung penuh (fully connected layer) dengan 1024 neuron
    tf.keras.layers.Dense(512, activation='relu'), # Ini adalah lapisan terhubung penuh (fully connected layer) dengan 512 neuron

  #karena ini multi-kelas maka kita akan menggunakan fungsi aktivasi softmax.

    tf.keras.layers.Dense(4, activation='softmax')
])

model.summary()

#kompilasi model dengan mengatur jenis pengklasifikasi, pengoptimal, acc yang kita inginkan di output

#menggunakan algoritma pengoptimalan RMSprop lebih disukai daripada stokastik
#gradient descent (SGD), karena RMSprop mengotomatiskan penyetelan laju pembelajaran untuk kita.
model.compile(optimizer = RMSprop(lr=1e-4),
              loss = 'categorical_crossentropy',metrics=['accuracy'])

"""5. Data Preprocessing"""

## Menggunakan Augmentasi

train_datagen = ImageDataGenerator(
      rescale=1./255.,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')
test_datagen = ImageDataGenerator(rescale=1./255.)

train_generator = train_datagen.flow_from_directory(
        training_dir,  # Ini adalah direktori sumber untuk gambar pelatihan
        target_size=(200, 200),  # Semua gambar akan diubah ukurannya menjadi 200x200
        batch_size=25,
        # Karena kami menggunakan kerugian sparse_categorical_crossentropy, kami memerlukan label kategorikal
        class_mode='categorical')

# Alur gambar validasi dalam batch 20 menggunakan generator test_datagen
validation_generator = test_datagen.flow_from_directory(
        validation_dir,
        target_size=(200, 200),
        batch_size=20,
        class_mode='categorical')

"""6. Training the Model"""

history = model.fit(
      train_generator,
      steps_per_epoch=59,  # 1200 images = batch_size * steps
      epochs=95,
      validation_data=validation_generator,
      validation_steps=30,
     verbose=1

) # 1200 images = batch_size * steps)

"""7. Visualization of the Results."""

# Commented out IPython magic to ensure Python compatibility.
# Plot grafik untuk akurasi dan kerugian pada pelatihan dan validasi
# %matplotlib inline
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()



plt.show()

"""8. Testing the Model (1)"""

import numpy as np
from google.colab import files
from keras.preprocessing import image
from tensorflow.keras.preprocessing import image
import numpy as np
uploaded = files.upload()

for fn in uploaded.keys():

  # memprediksi gambar
  path = fn
  img = image.load_img(path, target_size=(200, 200))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)


  plt.imshow(img)

  plt.show()

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(fn)
  print(classes)

  for i in classes:
    if classes[0][0]==1:
      print('ini adalah kucing Abyssian')
    elif classes[0][1]==1:
      print('ini adalah kucing Munchkin')
    elif classes[0][2]==1:
      print('ini adalah kucing Persian')
    elif classes[0][3]==1:
      print('ini adalah kucing Toyger')
    else:
        print('Bukan kucing')

"""9. Saving the model"""

model.save('/content/drive/MyDrive/klasifikasi_kucing_model.keras')

from tensorflow import keras
model = keras.models.load_model(model_dir)